{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Beyond text classification: Sequence-to-sequence learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A machine translation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-09 20:24:08--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "storage.googleapis.com (storage.googleapis.com) 해석 중... 142.251.130.27, 142.250.66.59, 172.217.24.91, ...\n",
      "다음으로 연결 중: storage.googleapis.com (storage.googleapis.com)|142.251.130.27|:80... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 2638744 (2.5M) [application/zip]\n",
      "저장 위치: `spa-eng.zip'\n",
      "\n",
      "spa-eng.zip         100%[===================>]   2.52M  4.98MB/s    /  0.5s    \n",
      "\n",
      "2023-11-09 20:24:09 (4.98 MB/s) - `spa-eng.zip' 저장함 [2638744/2638744]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "text_file = \"spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('She made friends with him in Boston.', '[start] Ella se hizo amiga suya en Boston. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Vectorizing the English and Spanish text pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 20:24:43.757410: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-09 20:24:43.757724: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 20:24:43.974623: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-11-09 20:24:44.034478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:46.791237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing datasets for the translation task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1],\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 20)\n",
      "inputs['spanish'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 20:24:49.613519: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Sequence-to-sequence learning with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**GRU-based encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embed_dim = 256\n",
    "latent_dim = 1024\n",
    "\n",
    "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = layers.Bidirectional(\n",
    "    layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**GRU-based decoder and the end-to-end model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training our recurrent sequence-to-sequence model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 20:24:55.577244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:56.834638: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_LEGACY_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_41/output/_23'\n",
      "2023-11-09 20:24:56.838685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:56.838756: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:57.482570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:58.251997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:58.975387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:24:58.975410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - ETA: 0s - loss: 1.5524 - accuracy: 0.4622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 20:29:13.966047: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:29:14.580256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:29:14.648075: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 20:29:14.776832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 281s 211ms/step - loss: 1.5524 - accuracy: 0.4622 - val_loss: 1.1327 - val_accuracy: 0.6137\n",
      "Epoch 2/15\n",
      "1302/1302 [==============================] - 272s 209ms/step - loss: 1.0841 - accuracy: 0.6381 - val_loss: 0.9595 - val_accuracy: 0.6884\n",
      "Epoch 3/15\n",
      "1302/1302 [==============================] - 273s 210ms/step - loss: 0.9355 - accuracy: 0.6778 - val_loss: 0.9132 - val_accuracy: 0.7100\n",
      "Epoch 4/15\n",
      "1302/1302 [==============================] - 272s 209ms/step - loss: 0.8882 - accuracy: 0.6897 - val_loss: 0.9424 - val_accuracy: 0.7031\n",
      "Epoch 5/15\n",
      "1302/1302 [==============================] - 272s 209ms/step - loss: 0.8973 - accuracy: 0.6921 - val_loss: 0.9301 - val_accuracy: 0.7114\n",
      "Epoch 6/15\n",
      "1302/1302 [==============================] - 275s 211ms/step - loss: 0.9465 - accuracy: 0.6880 - val_loss: 0.9275 - val_accuracy: 0.7132\n",
      "Epoch 7/15\n",
      "1302/1302 [==============================] - 274s 210ms/step - loss: 0.9908 - accuracy: 0.6825 - val_loss: 0.9337 - val_accuracy: 0.7111\n",
      "Epoch 8/15\n",
      "1302/1302 [==============================] - 277s 212ms/step - loss: 0.9929 - accuracy: 0.6894 - val_loss: 0.9326 - val_accuracy: 0.7165\n",
      "Epoch 9/15\n",
      "1302/1302 [==============================] - 278s 214ms/step - loss: 1.0083 - accuracy: 0.6882 - val_loss: 0.9394 - val_accuracy: 0.7160\n",
      "Epoch 10/15\n",
      "1302/1302 [==============================] - 277s 213ms/step - loss: 1.0122 - accuracy: 0.6896 - val_loss: 0.9392 - val_accuracy: 0.7188\n",
      "Epoch 11/15\n",
      "1302/1302 [==============================] - 277s 213ms/step - loss: 1.0277 - accuracy: 0.6858 - val_loss: 0.9672 - val_accuracy: 0.7099\n",
      "Epoch 12/15\n",
      "1302/1302 [==============================] - 276s 212ms/step - loss: 1.0302 - accuracy: 0.6873 - val_loss: 0.9606 - val_accuracy: 0.7147\n",
      "Epoch 13/15\n",
      "1302/1302 [==============================] - 276s 212ms/step - loss: 1.0355 - accuracy: 0.6858 - val_loss: 0.9485 - val_accuracy: 0.7206\n",
      "Epoch 14/15\n",
      "1302/1302 [==============================] - 277s 213ms/step - loss: 1.0288 - accuracy: 0.6894 - val_loss: 0.9587 - val_accuracy: 0.7180\n",
      "Epoch 15/15\n",
      "1302/1302 [==============================] - 277s 213ms/step - loss: 1.0725 - accuracy: 0.6737 - val_loss: 0.9891 - val_accuracy: 0.7053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bd596880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_rnn.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "seq2seq_rnn.fit(train_ds, epochs=15, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Translating new sentences with our RNN encoder and decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "I've only been online for ten minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 21:33:47.836357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 21:33:48.425473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 21:33:48.498932: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-09 21:33:49.077328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[start] no cómo no en no en no en no en no en no en no en no en no en\n",
      "-\n",
      "It's not easy to speak a foreign language.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[start] no cómo no cómo no cómo no cómo no cómo no cómo no cómo no les no les no les\n",
      "-\n",
      "He decided on the red car.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[start] la cómo la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela\n",
      "-\n",
      "Excuse my clumsiness.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[start] la cómo la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela\n",
      "-\n",
      "Tom realized that he had lost his wallet.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[start] la cómo la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela\n",
      "-\n",
      "Tom says he never lies to Mary, but he often does.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[start] no por momento por momento por este por este por este por este por este por este por este por\n",
      "-\n",
      "When he came, I was writing a letter.\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[start] Él [end]\n",
      "-\n",
      "No one got hurt.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[start] la cómo la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela\n",
      "-\n",
      "I worked all this week.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[start] la cómo la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad\n",
      "-\n",
      "It was tough to finish the work.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[start] la cómo la guerra la las la las la las la las la las la las la las la las\n",
      "-\n",
      "Tom should have gone to the dentist yesterday.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[start] la cómo la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela la escuela\n",
      "-\n",
      "What was the result?\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[start] no cómo del en del en del en del en del en del en del en del en del en\n",
      "-\n",
      "I'm trying to help a friend.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[start] la puedo la puedo la puedo la en la en la en la en la en la en la en\n",
      "-\n",
      "Where is the end of this line?\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[start] la cómo la en la en la en la en la en la en la en la en la en\n",
      "-\n",
      "Let's wait for another 5 minutes.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[start] no cómo no cómo no cómo no sabe no sabe no sabe no sabe no sabe no sabe no sabe\n",
      "-\n",
      "There's no need to set the table. We're going out to eat.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[start] la cómo la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad la ciudad\n",
      "-\n",
      "Tom is still crying.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[start] no cómo no en no en no en no en no en no en no en no en no en\n",
      "-\n",
      "Do you have a twin brother?\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[start] el es el es el es el es el es se es se es se es se es se es\n",
      "-\n",
      "How many employees do you have?\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[start] la cómo la cómo la cómo la cómo la en la en la en la en la en la en\n",
      "-\n",
      "She's busy with her work.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[start] la cómo la guerra la guerra la escuela la escuela la escuela la escuela la escuela la escuela la escuela\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
    "        next_token_predictions = seq2seq_rnn.predict(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Sequence-to-sequence learning with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):  \n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention( \n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),  \n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()  \n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The Transformer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        else:\n",
    "            padding_mask = mask\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Putting it all together: A Transformer for machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**PositionalEmbedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**End-to-end Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the sequence-to-sequence Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 14:53:25.628344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - ETA: 0s - loss: 1.6537 - accuracy: 0.4250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 14:59:37.525345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 409s 311ms/step - loss: 1.6537 - accuracy: 0.4250 - val_loss: 1.3183 - val_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 403s 309ms/step - loss: 1.2950 - accuracy: 0.5443 - val_loss: 1.1616 - val_accuracy: 0.5789\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 406s 312ms/step - loss: 1.1347 - accuracy: 0.5957 - val_loss: 1.0627 - val_accuracy: 0.6121\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 392s 301ms/step - loss: 1.0447 - accuracy: 0.6285 - val_loss: 1.0298 - val_accuracy: 0.6267\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 393s 302ms/step - loss: 0.9956 - accuracy: 0.6517 - val_loss: 1.0104 - val_accuracy: 0.6358\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.9601 - accuracy: 0.6697 - val_loss: 0.9937 - val_accuracy: 0.6456\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 399s 307ms/step - loss: 0.9330 - accuracy: 0.6838 - val_loss: 0.9944 - val_accuracy: 0.6482\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.9104 - accuracy: 0.6954 - val_loss: 0.9926 - val_accuracy: 0.6513\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.8904 - accuracy: 0.7058 - val_loss: 0.9922 - val_accuracy: 0.6539\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.8726 - accuracy: 0.7145 - val_loss: 0.9976 - val_accuracy: 0.6526\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.8552 - accuracy: 0.7225 - val_loss: 1.0018 - val_accuracy: 0.6537\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 399s 307ms/step - loss: 0.8394 - accuracy: 0.7288 - val_loss: 1.0146 - val_accuracy: 0.6491\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 399s 307ms/step - loss: 0.8249 - accuracy: 0.7351 - val_loss: 1.0149 - val_accuracy: 0.6553\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.8108 - accuracy: 0.7406 - val_loss: 1.0203 - val_accuracy: 0.6528\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 397s 305ms/step - loss: 0.7981 - accuracy: 0.7459 - val_loss: 1.0255 - val_accuracy: 0.6523\n",
      "Epoch 16/30\n",
      "1302/1302 [==============================] - 399s 307ms/step - loss: 0.7852 - accuracy: 0.7508 - val_loss: 1.0248 - val_accuracy: 0.6547\n",
      "Epoch 17/30\n",
      "1302/1302 [==============================] - 2484s 2s/step - loss: 0.7732 - accuracy: 0.7550 - val_loss: 1.0360 - val_accuracy: 0.6559\n",
      "Epoch 18/30\n",
      "1302/1302 [==============================] - 400s 307ms/step - loss: 0.7614 - accuracy: 0.7595 - val_loss: 1.0372 - val_accuracy: 0.6543\n",
      "Epoch 19/30\n",
      "1302/1302 [==============================] - 865s 665ms/step - loss: 0.7507 - accuracy: 0.7631 - val_loss: 1.0403 - val_accuracy: 0.6547\n",
      "Epoch 20/30\n",
      "1302/1302 [==============================] - 402s 309ms/step - loss: 0.7399 - accuracy: 0.7677 - val_loss: 1.0590 - val_accuracy: 0.6520\n",
      "Epoch 21/30\n",
      "1302/1302 [==============================] - 399s 307ms/step - loss: 0.7303 - accuracy: 0.7706 - val_loss: 1.0534 - val_accuracy: 0.6569\n",
      "Epoch 22/30\n",
      "1302/1302 [==============================] - 893s 686ms/step - loss: 0.7214 - accuracy: 0.7734 - val_loss: 1.0606 - val_accuracy: 0.6535\n",
      "Epoch 23/30\n",
      "1302/1302 [==============================] - 398s 306ms/step - loss: 0.7112 - accuracy: 0.7768 - val_loss: 1.0691 - val_accuracy: 0.6578\n",
      "Epoch 24/30\n",
      "1302/1302 [==============================] - 402s 309ms/step - loss: 0.7024 - accuracy: 0.7805 - val_loss: 1.0825 - val_accuracy: 0.6553\n",
      "Epoch 25/30\n",
      "1302/1302 [==============================] - 398s 306ms/step - loss: 0.6943 - accuracy: 0.7831 - val_loss: 1.0718 - val_accuracy: 0.6570\n",
      "Epoch 26/30\n",
      "1302/1302 [==============================] - 399s 306ms/step - loss: 0.6863 - accuracy: 0.7854 - val_loss: 1.0851 - val_accuracy: 0.6565\n",
      "Epoch 27/30\n",
      "1302/1302 [==============================] - 397s 305ms/step - loss: 0.6784 - accuracy: 0.7885 - val_loss: 1.0819 - val_accuracy: 0.6575\n",
      "Epoch 28/30\n",
      "1302/1302 [==============================] - 398s 306ms/step - loss: 0.6707 - accuracy: 0.7907 - val_loss: 1.0983 - val_accuracy: 0.6546\n",
      "Epoch 29/30\n",
      "1302/1302 [==============================] - 405s 311ms/step - loss: 0.6640 - accuracy: 0.7929 - val_loss: 1.1009 - val_accuracy: 0.6587\n",
      "Epoch 30/30\n",
      "1302/1302 [==============================] - 397s 305ms/step - loss: 0.6567 - accuracy: 0.7957 - val_loss: 1.1034 - val_accuracy: 0.6536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d476d90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Translating new sentences with our Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Why is Tom there?\n",
      "[start] por qué está allí tom [end]\n",
      "-\n",
      "I ran around the field.\n",
      "[start] yo me he dejado de por el campo [end]\n",
      "-\n",
      "He took my umbrella without bothering to ask.\n",
      "[start] se sacó el paraguas sin que sin pedirle agua [end]\n",
      "-\n",
      "The house is on the most level part of the ground.\n",
      "[start] la casa está al hombre más parte del ahora del piso [end]\n",
      "-\n",
      "She watched him and the other boys playing baseball.\n",
      "[start] ella le vio y el otro béisbol es juego de jugar al béisbol [end]\n",
      "-\n",
      "From there, one could see perfectly.\n",
      "[start] desde un día podía ver a la discusión [end]\n",
      "-\n",
      "The boy said that the taxi vanished into the fog.\n",
      "[start] el niño dijo que el parque [UNK] que [UNK] en la cena [end]\n",
      "-\n",
      "I am good.\n",
      "[start] estoy bueno [end]\n",
      "-\n",
      "Open the box.\n",
      "[start] cierra la caja [end]\n",
      "-\n",
      "Tom is behind you.\n",
      "[start] tom está detrás de ti [end]\n",
      "-\n",
      "Don't make any loud noises.\n",
      "[start] no hagas daño el [UNK] [end]\n",
      "-\n",
      "Hebrew is my mother tongue.\n",
      "[start] la [UNK] es mi lengua la lengua de edad [end]\n",
      "-\n",
      "The hard work paid off.\n",
      "[start] el trabajo duro se sacó el [UNK] [end]\n",
      "-\n",
      "All the houses were shaking and alarms were ringing everywhere.\n",
      "[start] todas las casas estaban la con el qué estaban de te [UNK] y se [UNK] todas todas las [UNK] [end]\n",
      "-\n",
      "Many peasants died during the drought.\n",
      "[start] muchos [UNK] murieron durante la que [end]\n",
      "-\n",
      "The lake is four miles across.\n",
      "[start] el lago tiene cuatro millas de al otro [end]\n",
      "-\n",
      "We will defeat them.\n",
      "[start] los [UNK] [end]\n",
      "-\n",
      "Let's go back to the hotel.\n",
      "[start] vamos a ir a trabajo [end]\n",
      "-\n",
      "That house is mine.\n",
      "[start] esa casa es mía [end]\n",
      "-\n",
      "Did you watch TV last night?\n",
      "[start] has visto la televisión anoche [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 21:09:58.690459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - ETA: 0s - loss: 1.3238 - accuracy: 0.4939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 21:15:11.413929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 346s 264ms/step - loss: 1.3238 - accuracy: 0.4939 - val_loss: 0.8823 - val_accuracy: 0.6098\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 343s 263ms/step - loss: 0.6980 - accuracy: 0.6534 - val_loss: 0.7362 - val_accuracy: 0.6533\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.4463 - accuracy: 0.7454 - val_loss: 0.7154 - val_accuracy: 0.6632\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 341s 262ms/step - loss: 0.3264 - accuracy: 0.8023 - val_loss: 0.7345 - val_accuracy: 0.6708\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.2611 - accuracy: 0.8349 - val_loss: 0.7723 - val_accuracy: 0.6723\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 340s 262ms/step - loss: 0.2190 - accuracy: 0.8561 - val_loss: 0.8228 - val_accuracy: 0.6694\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.1898 - accuracy: 0.8718 - val_loss: 0.8712 - val_accuracy: 0.6704\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 1432s 1s/step - loss: 0.1665 - accuracy: 0.8843 - val_loss: 0.8717 - val_accuracy: 0.6731\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 967s 743ms/step - loss: 0.1462 - accuracy: 0.8963 - val_loss: 0.8970 - val_accuracy: 0.6759\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.1312 - accuracy: 0.9053 - val_loss: 0.9164 - val_accuracy: 0.6762\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.1188 - accuracy: 0.9129 - val_loss: 0.9250 - val_accuracy: 0.6765\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 341s 262ms/step - loss: 0.1086 - accuracy: 0.9191 - val_loss: 0.9560 - val_accuracy: 0.6800\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0990 - accuracy: 0.9254 - val_loss: 0.9726 - val_accuracy: 0.6799\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0913 - accuracy: 0.9309 - val_loss: 0.9990 - val_accuracy: 0.6817\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 339s 260ms/step - loss: 0.0857 - accuracy: 0.9346 - val_loss: 1.0067 - val_accuracy: 0.6812\n",
      "Epoch 16/30\n",
      "1302/1302 [==============================] - 339s 261ms/step - loss: 0.0800 - accuracy: 0.9387 - val_loss: 1.0281 - val_accuracy: 0.6795\n",
      "Epoch 17/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0767 - accuracy: 0.9409 - val_loss: 1.0407 - val_accuracy: 0.6838\n",
      "Epoch 18/30\n",
      "1302/1302 [==============================] - 339s 261ms/step - loss: 0.0711 - accuracy: 0.9449 - val_loss: 1.0717 - val_accuracy: 0.6820\n",
      "Epoch 19/30\n",
      "1302/1302 [==============================] - 339s 260ms/step - loss: 0.0677 - accuracy: 0.9472 - val_loss: 1.1023 - val_accuracy: 0.6812\n",
      "Epoch 20/30\n",
      "1302/1302 [==============================] - 341s 262ms/step - loss: 0.0642 - accuracy: 0.9501 - val_loss: 1.0959 - val_accuracy: 0.6828\n",
      "Epoch 21/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0613 - accuracy: 0.9521 - val_loss: 1.1020 - val_accuracy: 0.6825\n",
      "Epoch 22/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0578 - accuracy: 0.9547 - val_loss: 1.1109 - val_accuracy: 0.6847\n",
      "Epoch 23/30\n",
      "1302/1302 [==============================] - 342s 262ms/step - loss: 0.0573 - accuracy: 0.9555 - val_loss: 1.1014 - val_accuracy: 0.6861\n",
      "Epoch 24/30\n",
      "1302/1302 [==============================] - 341s 262ms/step - loss: 0.0540 - accuracy: 0.9574 - val_loss: 1.1247 - val_accuracy: 0.6856\n",
      "Epoch 25/30\n",
      "1302/1302 [==============================] - 339s 261ms/step - loss: 0.0503 - accuracy: 0.9603 - val_loss: 1.1575 - val_accuracy: 0.6824\n",
      "Epoch 26/30\n",
      "1302/1302 [==============================] - 343s 264ms/step - loss: 0.0511 - accuracy: 0.9601 - val_loss: 1.1286 - val_accuracy: 0.6859\n",
      "Epoch 27/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0485 - accuracy: 0.9618 - val_loss: 1.1486 - val_accuracy: 0.6866\n",
      "Epoch 28/30\n",
      "1302/1302 [==============================] - 340s 261ms/step - loss: 0.0464 - accuracy: 0.9635 - val_loss: 1.1631 - val_accuracy: 0.6857\n",
      "Epoch 29/30\n",
      "1302/1302 [==============================] - 341s 262ms/step - loss: 0.0452 - accuracy: 0.9645 - val_loss: 1.1690 - val_accuracy: 0.6858\n",
      "Epoch 30/30\n",
      "1302/1302 [==============================] - 1176s 904ms/step - loss: 0.0439 - accuracy: 0.9653 - val_loss: 1.1791 - val_accuracy: 0.6856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ba711f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "### change hyperparameter values\n",
    "embed_dim = 256  # (25 -> 256)\n",
    "dense_dim = 2048  # (1024 -> 2048)\n",
    "num_heads = 6  # (8 -> 6)\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.4)(x)  # Dropout (0.3 -> 0.4)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "transformer.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),  # learning rate (R -> 1e-3)\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "He paid $20 for the lipstick.\n",
      "[start] Él pagó se levantó por la [UNK] [end]\n",
      "-\n",
      "She advised him to stay in bed for two more days.\n",
      "[start] le aconsejó que se [UNK] en la cama a dos días [end]\n",
      "-\n",
      "A fire broke out in the supermarket last night.\n",
      "[start] un incendio en el vecindario la noche [end]\n",
      "-\n",
      "She is a very intelligent young lady.\n",
      "[start] ella es una persona muy joven [end]\n",
      "-\n",
      "World War I broke out in 1914.\n",
      "[start] la guerra se me da pasando bien [end]\n",
      "-\n",
      "I've kept my weight down even though many of my friends have gained weight as they've grown older.\n",
      "[start] he tomado el peso de pesar de tener muchos amigos que mi propio peso [end]\n",
      "-\n",
      "That's very dangerous.\n",
      "[start] eso es muy peligroso [end]\n",
      "-\n",
      "I've never been spoken to like that.\n",
      "[start] nunca he hablado como eso [end]\n",
      "-\n",
      "I shouldn't have to do all this work by myself.\n",
      "[start] no debí tener que hacer todo el trabajo yo solo [end]\n",
      "-\n",
      "Don't judge people by their appearance.\n",
      "[start] no [UNK] a la gente de su apariencia [end]\n",
      "-\n",
      "Let's wait here until he comes back.\n",
      "[start] esperemos aquí hasta que él venga [end]\n",
      "-\n",
      "He generally goes home at five o'clock.\n",
      "[start] Él acaba de ir a casa a las cinco [end]\n",
      "-\n",
      "I would never question his honesty.\n",
      "[start] nunca [UNK] la pregunta [end]\n",
      "-\n",
      "I've already finished reading this book.\n",
      "[start] ya he terminado de leer este libro [end]\n",
      "-\n",
      "Tom needs the ladder.\n",
      "[start] tom necesita la escalera [end]\n",
      "-\n",
      "I like my chicken wings with barbeque sauce.\n",
      "[start] me gusta mi torta con las elecciones [end]\n",
      "-\n",
      "My family is from Malaysia.\n",
      "[start] mi familia es de [UNK] [end]\n",
      "-\n",
      "It's not very windy today.\n",
      "[start] hoy no hace mucho viento [end]\n",
      "-\n",
      "What bit you?\n",
      "[start] qué te has hecho [end]\n",
      "-\n",
      "I hate being photographed.\n",
      "[start] odio estar siendo [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "# Test Translating\n",
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence]) \n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts) \n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter11_part04_sequence-to-sequence-learning.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
